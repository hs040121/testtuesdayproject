## 특징 공학 및 딥러닝 앙상블 기반 AI 이미지 진위 판별 시스템

* **과목명**: 인공지능개발프로젝트
* **제출일**: 2025년 12월 15일
* **이름**: 방현석

---

## 1. 서론

### 1.1 프로젝트 개요

* **프로젝트명**: **Fake Image Detector (AI Image Authenticity Analyzer)**
* **개발 목표**: 사용자가 업로드한 이미지가 실제 카메라로 촬영된 **Real** 사진인지, 생성형 AI(Generative AI) 기술로 합성된 **Fake** 이미지인지 판별하는 고성능 웹 애플리케이션 개발.
* **핵심 접근**: 단일 딥러닝 모델의 블랙박스 한계를 극복하기 위해, 이미지 고유의 물리적 특성(압축률, 텍스처)을 분석하는 **특징 공학(Feature Engineering)** 기반 모델을 직접 구축하고, 이를 최신 **Vision Transformer(ViT)** 모델과 결합하여 판별 신뢰도를 극대화함.

### 1.2 개발 배경 및 필요성

* **사회적 문제**: Deepfake 및 AI 생성 이미지 기술의 발전으로 가짜 뉴스와 저작권 침해 등 사회적 혼란이 가중되고 있음.
* **기술적 한계**: 기존 CNN 기반 딥러닝 모델은 데이터 편향에 취약하고 판별 근거를 제시하지 못하는 한계가 있음.
* **해결 방안**: 이미지의 **압축 아티팩트(Compression Artifacts)**와 주파수 영역의 통계적 특성을 분석하여 설명 가능한 판별 근거를 제공하는 시스템이 필요함.

---

## 2. 시스템 아키텍처 및 구현

### 2.1 전체 시스템 구조

본 시스템은 **FastAPI**를 기반으로 한 고성능 백엔드 서버와 **Glassmorphism UI**를 적용한 반응형 프론트엔드로 구성된다.

* **Frontend**: 사용자로부터 이미지를 입력받아 비동기적으로 서버에 분석을 요청하고, 결과 및 시각화 데이터를 렌더링함.
* **Backend**: 두 개의 독립적인 분석 엔진(Custom Model, ViT Model)을 병렬로 구동하여 교차 검증을 수행함.

### 2.2 핵심 알고리즘 (Dual Analysis Engine)

#### Engine A: Custom Forensic Model (직접 개발)

* **알고리즘**: RandomForest Classifier (Ensemble Learning)

**특징 추출 (Feature Extraction Pipeline)**

* **ELA (Error Level Analysis)**
  이미지를 4가지 품질 단계(Quality = [90, 85, 80, 75])로 재압축하여 원본과의 차이(Error Map)를 생성함. 각 단계별 히스토그램을 추출하여 **40차원 특징 벡터**를 생성함. 이는 AI 생성 이미지가 재압축 시 특정 주파수 대역에서 손실률이 다르다는 점을 이용함.

* **LBP (Local Binary Patterns)**
  4가지 반경(Radius = [1, 2, 3, 4])에서 픽셀 주변의 미세 텍스처 패턴을 분석하여 **88차원 특징 벡터**를 생성함. AI 특유의 부자연스러운 고주파 노이즈를 탐지하는 데 탁월함.

* **데이터 전처리**
  StandardScaler를 적용하여 **128차원 특징 벡터**의 스케일을 정규화함으로써 모델의 수렴 속도와 정확도를 향상시킴.

* **성능**
  자체 구축한 약 20,000장 규모의 데이터셋에서 **테스트 정확도 91.93%** 달성.

* **설명 가능성**
  Grid Analysis를 통해 이미지 내 조작 의심 영역(Hotspot)을 탐지하여 시각적으로 제공함.

#### Engine B: Vision Transformer (ViT) Model (비교군)

* **모델**: Hugging Face `vit-base-patch16-224-in21k-ai-or-real`
* **방식**: 이미지를 16×16 패치로 분할하여 Self-Attention 메커니즘을 통해 전역적 문맥(Global Context)을 학습함.
* **역할**: 특징 공학 모델이 놓칠 수 있는 고차원적인 픽셀 패턴을 감지하여 **2차 검증** 수행.
* **최적화**: Softmax 함수를 적용하여 클래스 간 확률 합계가 100%가 되도록 출력값을 정규화함.

---

## 3. 개발 환경

| 구분               | 상세 내용                                       |
| ---------------- | ------------------------------------------- |
| Language         | Python 3.10+, JavaScript (ES6)              |
| Backend          | FastAPI, Uvicorn, Python-multipart          |
| Frontend         | HTML5, CSS3, jQuery, Chart.js, Bootstrap 5  |
| ML Libraries     | Scikit-learn, Joblib, PyTorch, Transformers |
| Image Processing | OpenCV (cv2), Pillow, Scikit-image          |
| Dataset          | Real/Fake 이미지 약 20,000장 (직접 수집 및 레이블링)      |
| IDE              | PyCharm Professional, VS Code               |

---

## 4. 문제 해결 및 성능 최적화

### 4.1 데이터 편향(Bias) 문제 해결

* **문제**: 초기 모델이 특정 Real 이미지(예: 어두운 사진)를 Fake로 오판하는 현상 발생.
* **분석**: 학습 로그 분석 결과, 학습 데이터 경로에 한글이 포함된 경우 OpenCV `imread` 함수가 이미지를 읽지 못해 **0으로 채워진 벡터(Zero Vector)**가 학습 데이터로 대거 유입됨을 확인함. 모델이 “0 벡터 = 가짜”라는 잘못된 규칙을 학습함.
* **해결**: `cv2.imdecode`와 `numpy.frombuffer`를 사용하여 파일 스트림을 바이너리로 직접 읽는 방식으로 코드를 전면 수정함. 손상된 파일은 학습 파이프라인에서 제외(None 반환)하는 로직을 추가하여 데이터 무결성을 확보함.

### 4.2 전처리 파이프라인 불일치 해결

* **문제**: 재학습 후에도 웹 서비스 상의 정확도가 예상보다 낮게 나타남.
* **분석**: 학습 코드(`train_model.py`)는 ELA 시각화 이미지(밝기 증폭)에서 특징을 추출했으나, 서버 코드(`main.py`)는 원본 차이 이미지에서 추출하는 불일치를 발견함.
* **해결**: 서버 코드의 특징 추출 로직을 학습 코드와 완벽하게 동기화(`ela_image_visual` 사용)하여 입력 데이터 분포(Distribution)를 일치시킴.

### 4.3 모델 성능 향상 (Accuracy 91.93%)

* **시도**: 단일 품질(Q=90) ELA와 단일 반경(R=1) LBP만으로는 복잡한 AI 이미지를 탐지하는 데 한계가 존재함.
* **개선**: ELA 품질을 4단계로 확장하고 LBP 반경을 4단계로 확장하여 특징 벡터 차원을 증가(Feature Expansion)시킴. 이를 통해 다양한 해상도와 압축률에 강건한 모델을 구축하여 **정확도 91.93%**를 달성함.

---

## 5. 결론 및 기대 효과

본 프로젝트는 단순히 기존 라이브러리를 활용하는 수준을 넘어, **이미지 포렌식 이론(ELA, LBP)**을 실제 코드로 구현하고 **머신러닝 파이프라인 전 과정(수집–전처리–학습–평가–배포)**을 직접 수행했다는 점에서 의의가 있다.

특히 **91.93%**라는 높은 정확도는 최신 딥러닝 모델에 의존하지 않고도, 데이터의 특성을 정확히 파악하고 적절한 특징 공학을 적용한다면 AI 생성 이미지를 효과적으로 탐지할 수 있음을 증명한다. 또한 최신 ViT 모델과의 결합을 통해 시스템의 신뢰성을 확보하고, 완성도 높은 웹 인터페이스를 통해 실용적인 AI 서비스의 가능성을 확인하였다.

향후 본 시스템은 가짜 뉴스 탐지, 디지털 콘텐츠 저작권 보호, 소셜 미디어 필터링 등 다양한 분야에서 신뢰할 수 있는 디지털 환경을 조성하는 데 기여할 수 있을 것이다.
