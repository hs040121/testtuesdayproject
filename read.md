# 특징 공학 기반 포렌식 분석과 딥러닝 앙상블을 활용한 AI 이미지 진위 판별 시스템

## 1. 서론

### 1.1 프로젝트 개요

본 프로젝트는 사용자가 업로드한 이미지가 **실제 카메라로 촬영된 사진(Real)** 인지, 혹은 **생성형 AI에 의해 합성된 이미지(Fake)** 인지를 판별하는 웹 기반 AI 시스템을 개발하는 것을 목표로 한다. 본 시스템은 *DeepDetect Pro*라는 이름으로 구현되었으며, 단일 딥러닝 분류기에 의존하는 기존 방식과 달리 **특징 공학 기반 이미지 포렌식 모델**과 **Vision Transformer(ViT) 기반 딥러닝 모델**을 결합한 **이중 판별 구조(Dual Analysis Engine)** 를 핵심 설계 개념으로 채택하였다.

본 프로젝트의 핵심적인 특징은 단순히 판별 결과만을 제공하는 데 그치지 않고, “왜 해당 이미지가 AI 생성 이미지로 판단되었는가?”에 대한 **분석 근거를 사용자에게 직관적으로 제시**하는 데 있다. 이를 위해 이미지 압축 과정에서 발생하는 오류 분포와 텍스처 패턴의 불일치를 분석하는 **설명 가능한 AI(eXplainable AI, XAI)** 관점의 접근을 중점적으로 적용하였다.

### 1.2 개발 배경 및 필요성

최근 생성형 AI 기술의 비약적인 발전으로 인해 실제 사진과 육안으로 구분하기 어려운 고품질 합성 이미지가 대량으로 생성되고 있다. 이러한 이미지들은 가짜 뉴스 확산, 디지털 증거 위·변조, 저작권 침해 등 다양한 사회적·법적 문제를 유발할 수 있다.

기존의 CNN 기반 또는 단일 딥러닝 모델 중심의 이미지 판별 방식은 높은 정확도를 보이는 경우도 있으나, 특정 데이터셋이나 생성 모델에 과도하게 의존하는 **일반화 한계**와 더불어, 판별 결과에 대한 **설명 가능성이 부족**하다는 문제점을 가진다. 이에 따라 이미지의 물리적 생성·압축 과정에서 자연스럽게 발생하는 흔적을 분석하는 **포렌식 기반 접근 방식**과 딥러닝 모델을 결합한 보다 신뢰도 높은 AI 이미지 판별 시스템의 필요성이 대두되었다.

---

## 2. 시스템 설계 및 전체 구조

본 장에서는 제안하는 AI 이미지 진위 판별 시스템의 전체 구조와 설계 의도를 설명한다. Figure 1은 본 프로젝트에서 사용한 대규모 학습 데이터와 모델 학습 결과를, Figure 2는 실제 서비스 환경에서 구현된 웹 기반 사용자 인터페이스를 각각 보여준다.

### 2.1 시스템 아키텍처

본 시스템은 **FastAPI 기반 백엔드 서버**와 **HTML/CSS/JavaScript 기반 프론트엔드**로 구성된 웹 애플리케이션 형태로 구현되었다.

* **Frontend**
  사용자는 웹 인터페이스를 통해 이미지를 업로드하며, 업로드된 이미지는 비동기 방식으로 서버에 전달된다. 분석 결과는 최종 판별 문구, 모델별 확률 비교 차트, 그리고 조작 의심 영역 시각화 형태로 제공된다.

* **Backend**
  서버는 업로드된 이미지를 두 개의 독립적인 분석 엔진(Custom Model, ViT Model)에 동시에 전달하고, 각 엔진의 결과를 종합하여 최종 판별 결과를 생성한다.

### 2.2 Dual Analysis Engine 구조

#### 2.2.1 Engine A: 특징 공학 기반 포렌식 모델 (Custom Model)

Figure 1에 제시된 바와 같이, 본 프로젝트에서는 약 39,000장의 Real/Fake 이미지 데이터셋을 활용하여 특징 공학 기반 포렌식 모델을 학습하였다.

Engine A는 이미지 포렌식 이론을 직접 구현한 모델로, **RandomForest 분류기**를 기반으로 한다.

* **특징 추출 구성**

  * **ELA (Error Level Analysis)**
    입력 이미지를 4가지 JPEG 품질(Q = 90, 85, 80, 75)로 재압축한 뒤 원본 이미지와의 차이를 계산한다. 각 ELA 결과 이미지에서 히스토그램을 추출하여 **총 40차원 특징 벡터**를 생성하였다. 이는 AI 생성 이미지가 재압축 과정에서 비자연적인 주파수 손실 패턴을 보이는 경향을 이용한 것이다.

  * **LBP (Local Binary Pattern)**
    반경 R = 1, 2, 3, 4에 대해 국소 텍스처 패턴을 분석하고, 각 반경별 히스토그램을 결합하여 **88차원 특징 벡터**를 생성하였다. 이를 통해 AI 이미지에서 자주 나타나는 미세한 텍스처 불균형을 효과적으로 탐지할 수 있다.

* **전처리 및 학습 과정**
  ELA와 LBP 특징을 결합한 **128차원 특징 벡터**에 대해 StandardScaler를 적용하여 정규화한 후 RandomForest 분류기를 학습하였다.

* **성능 평가**
  직접 수집 및 레이블링한 약 39,000장의 실제 사진 및 AI 생성 이미지 데이터셋을 활용하여 실험한 결과, **테스트 정확도 91.93%**를 달성하였다.

* **설명 가능성(XAI)**
  ELA 결과 이미지를 4×4 Grid로 분할하고, 평균 오류 값이 가장 높은 영역을 **조작 의심 영역(Hotspot)** 으로 정의하여 시각적으로 사용자에게 제공하였다.

#### 2.2.2 Engine B: Vision Transformer(ViT) 기반 딥러닝 모델

Figure 3은 본 프로젝트의 시스템이 실제 AI 생성 이미지를 판별한 사례를 보여주며, 해당 결과는 본 절에서 설명하는 ViT 모델의 출력 결과를 포함한다.

Engine B는 딥러닝 기반의 보조 판별 엔진으로, Hugging Face에서 제공하는 **Vision Transformer(ViT)** 모델을 활용하였다.

* **모델**: `vit-base-patch16-224-in21k-ai-or-real`
* **동작 방식**: 이미지를 16×16 크기의 패치로 분할한 뒤 Self-Attention 메커니즘을 통해 전역 문맥 정보를 학습한다.
* **역할**: 특징 공학 기반 모델이 놓칠 수 있는 고차원 픽셀 패턴을 보완적으로 분석하는 **2차 검증 모델**로 활용된다.
* **출력 처리**: Softmax 함수를 적용하여 Real과 Fake 클래스의 확률 합이 100%가 되도록 정규화하였다.

---

## 3. 개발 환경

| 구분               | 내용                                         |
| ---------------- | ------------------------------------------ |
| Language         | Python 3.10+, JavaScript (ES6)             |
| Backend          | FastAPI, Uvicorn                           |
| Frontend         | HTML5, CSS3, Bootstrap 5, jQuery, Chart.js |
| ML Libraries     | Scikit-learn, PyTorch, Transformers        |
| Image Processing | OpenCV, Pillow, Scikit-image               |
| Dataset          | Real / Fake 이미지 약 39,000장                  |
| IDE              | PyCharm, VS Code                           |

---

## 4. 문제 해결 과정 및 성능 개선

### 4.1 데이터 편향 및 로딩 오류 문제 해결

초기 학습 단계에서 일부 실제 사진이 반복적으로 Fake로 오판되는 문제가 발생하였다. 분석 결과, 이미지 경로에 한글이 포함된 경우 OpenCV의 `imread` 함수가 이미지를 정상적으로 로드하지 못해 **0 벡터 특징이 학습 데이터에 포함되는 현상**이 원인임을 확인하였다.

이를 해결하기 위해 이미지 파일을 바이너리 스트림 형태로 직접 읽는 방식(`cv2.imdecode`와 `numpy.frombuffer` 활용)으로 전면 수정하였으며, 특징 추출에 실패한 데이터는 학습 과정에서 제외하도록 처리하여 데이터 무결성을 확보하였다.

### 4.2 학습–서비스 전처리 불일치 문제

모델 재학습 이후에도 웹 서비스 환경에서의 판별 성능이 기대보다 낮게 나타나는 문제가 발생하였다. 원인 분석 결과, 학습 코드와 서버 코드 간 **ELA 특징 추출 기준 이미지가 서로 다르게 적용**되고 있음을 확인하였다.

이에 따라 서버 측 특징 추출 과정을 학습 코드와 완전히 동일하게 수정하여 입력 데이터 분포를 일치시켰고, 그 결과 서비스 환경에서도 안정적인 성능을 확보할 수 있었다.

### 4.3 특징 확장 기반 성능 향상

단일 품질 ELA 및 단일 반경 LBP만으로는 다양한 생성형 AI 이미지의 특성을 충분히 포착하기 어렵다는 한계가 있었다. 이를 개선하기 위해 다중 품질 ELA와 다중 반경 LBP로 특징을 확장하였으며, 그 결과 모델의 일반화 성능이 향상되어 **최종 테스트 정확도 91.93%**를 달성하였다.

---

## 5. 비교 실험: 상용 AI 탐지기와의 성능 비교 사례

본 장에서는 Figure 3과 Figure 4에 제시된 동일한 AI 생성 이미지를 대상으로, 본 프로젝트의 시스템과 상용 AI 탐지기 간의 판별 결과를 비교 분석한다.

### 5.1 비교 실험 개요

본 비교 실험에서는 보고서에 제시된 **Figure 1~Figure 4**의 이미지를 활용하여, 데이터 학습 결과부터 실제 서비스 환경에서의 탐지 성능까지를 단계적으로 검증하였다. 본 프로젝트에서 사용한 학습 데이터 규모(약 39,000장)와 모델 성능, 그리고 동일한 AI 생성 이미지에 대한 상용 AI 탐지기와의 판별 결과를 시각적으로 비교함으로써, 제안 시스템의 실효성을 명확히 분석하고자 하였다.

본 프로젝트의 실효성을 보다 명확히 검증하기 위해, 동일한 AI 생성 이미지를 대상으로 **본 시스템(DeepDetect Pro)**과 **상용 AI 이미지 탐지 서비스(Illuminarty)**의 판별 결과를 비교하는 실험을 수행하였다. 비교 대상 이미지는 최신 생성형 AI 모델로 생성된 고품질 이미지로, 육안으로는 실제 사진과 구분이 매우 어려운 사례를 선정하였다.

해당 이미지는 보고서 본문에 Figure 형태로 첨부하였으며, 동일한 원본 이미지를 각 탐지 시스템에 입력하여 결과를 비교하였다.

### 5.2 비교 실험 결과

* **Illuminarty (상용 AI 탐지기)**

  * AI Probability: **15%**
  * 판별 결과: 실제 사진으로 판단 (AI 생성 이미지 탐지 실패)

* **DeepDetect Pro (본 프로젝트)**

  * Custom Model (ELA+LBP): AI 생성 이미지로 판별
  * ViT 모델: AI 생성 이미지 확률 우세
  * 종합 판별 결과: **AI 조작 의심**

즉, 동일한 AI 생성 이미지에 대해 상용 탐지 서비스는 AI 생성 가능성을 낮게 평가한 반면, 본 프로젝트의 시스템은 포렌식 기반 특징 분석과 딥러닝 모델의 교차 검증을 통해 AI 생성 가능성을 탐지할 수 있었다.

### 5.3 탐지 실패 원인 분석

상용 AI 탐지기가 해당 이미지를 탐지하지 못한 원인은 다음과 같이 분석된다.

1. **고품질 생성 이미지의 후처리 문제**
   최신 생성형 AI 이미지는 자연스러운 조명, 노이즈, 색 분포를 갖도록 후처리되는 경우가 많아, 딥러닝 모델이 학습한 전형적인 AI 패턴이 약화된다.

2. **데이터 편향 및 일반화 한계**
   상용 탐지기는 특정 생성 모델이나 스타일에 최적화되어 학습되었을 가능성이 있으며, 학습 데이터에 포함되지 않은 유형의 이미지에 대해서는 탐지 성능이 저하될 수 있다.

3. **단일 모델 의존 구조의 한계**
   딥러닝 기반 단일 모델은 전역적 패턴에는 강점을 가지나, JPEG 압축 오류나 미세 텍스처 불일치와 같은 저수준 포렌식 단서를 충분히 활용하지 못하는 한계가 있다.

반면, 본 프로젝트는 **포렌식 기반 특징 공학 모델과 딥러닝 모델을 결합한 이중 판별 구조**를 통해, 단일 모델이 놓칠 수 있는 단서를 보완적으로 포착할 수 있었다.

---

## 6. 종합 논의

본 비교 실험은 AI 이미지 탐지 문제에서 **단일 고성능 모델에 대한 의존이 반드시 최선의 해법이 아님**을 시사한다. 특히, 상용 서비스조차 탐지에 실패한 사례를 통해, 포렌식 기반 접근 방식의 실질적인 유효성을 확인할 수 있었다.

또한 본 프로젝트는 단순 정확도 지표를 넘어, **판별 근거를 시각적으로 제시하는 설명 가능한 구조(XAI)**를 도입함으로써, 실제 서비스 환경에서의 신뢰성과 활용 가능성을 높였다.

---

## 7. 결론 및 기대 효과

본 캡스톤 프로젝트에서는 특징 공학 기반 이미지 포렌식 기법과 Vision Transformer 기반 딥러닝 모델을 결합한 **AI 이미지 진위 판별 시스템**을 설계·구현하였다. 데이터 수집, 전처리, 학습, 평가, 웹 서비스 배포까지 전 과정을 직접 수행함으로써, 이론과 실무를 연결하는 종합적인 AI 시스템을 완성하였다.

특히 상용 AI 탐지기가 탐지하지 못한 고품질 AI 생성 이미지에 대해서도, 본 시스템은 포렌식 특징과 딥러닝 모델의 교차 검증을 통해 AI 조작 가능성을 탐지할 수 있음을 실험적으로 확인하였다.

향후 본 시스템은 가짜 뉴스 탐지, 디지털 포렌식, 저작권 보호, 소셜 미디어 콘텐츠 검증 등 다양한 분야에서 신뢰도 높은 보조 판별 도구로 활용될 수 있을 것으로 기대된다.
